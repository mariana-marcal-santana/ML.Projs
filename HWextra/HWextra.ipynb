{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Machine Learning Homework 4\n",
    "Done by:\n",
    "Mariana Santana 106992\n",
    "Pedro Leal 106154\n",
    "LEIC-A\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the breast_cancer dataset data = datasets.load_breast_cancer()  with binary target variable y=‘malignant’. Split it 70% for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "General imports and variables for all exercises; run this cell before any other\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Perform logistic regression and indicate the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9532163742690059\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing the logistic regression a few times and computing the average of the results, we obtained an accuracy of around 0.96."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Perform EM clustering on the training data set with different number k of clusters. Evaluate the quality of the clusterings using Silhouette. Is the number of clusters correlated with the quality of clustering? Which is the optimal k? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Scores: [0.547417880628131, 0.5298840922143213, 0.46746093329440225, 0.4441541716211507, 0.4213965673816725, 0.41281288379876063, 0.4202669805124573, 0.40423860171733733]\n",
      "Optimal number of clusters: 2\n"
     ]
    }
   ],
   "source": [
    "k_values = range(2, 10)\n",
    "\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    gmm = GaussianMixture(n_components=k)\n",
    "    gmm.fit(X_train)\n",
    "    labels = gmm.predict(X_train)\n",
    "    score = silhouette_score(X_train, labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "print(\"Silhouette Scores:\", silhouette_scores)\n",
    "optimal_k = k_values[np.argmax(silhouette_scores)]\n",
    "print(\"Optimal number of clusters:\", optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon performing EM clustering, we obtained the silhouette scores for the different number of clusters ([0.6953546812827253, 0.6460072951798395, 0.44240066859293997, 0.40975176230240173, 0.4342973431576532, 0.4192675100180935, 0.4273557130544327, 0.4203979188373632] in order from 2 to 9 clusters).\n",
    "\n",
    "We also know that overall silhouette score (average of the silhouettes of the individual points of the dataset) is used to evaluate the quality of clustering results. The individual silhouettes can range between -1 and 1 where lower values mean that the point has probably been assigned to the wrong cluster while higher values mean that the point matches nearly perfectly its neighbors (points of the same cluster) and very poorly points of different cluster, resulting in a better assignment of points to clusters. The overall silhouette of the model ranges between the same values as the previously explained silhouettes. For genereal interpretation, lower values suggest bad organization of points in clusters while values closer to 1 correspond to a lower intra-cluster distance (points in the same cluster are close to eachother) and higher inter-cluster distance (clusters are far apart from eachother).\n",
    "\n",
    "Given this, when analysing the varying results, we concluded that the number of clusters impacts the model's quality of clustering. This happens because the number of clusters has an effect in cohesion and separation (with too few cluster the model has low separation and high cohesion - points within clusters are not very similar and clusters may overlap and with too many clusters can lead to overfitting - clusters become too small and lose their generality). \n",
    "\n",
    "After this analysis, we concluded that there needed to be a balance in the model's cohesion and separation which are directly linked to its silhouette: the higher silhouette value belonged to k=2 (0.6953546812827253) which corresponds to the optimal number of cluster for this model and this data. This conclusion makes a lot of sense for this exercise because there are 2 possible outcomes (benign and malignant) and therefore 2 clusters to classify observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Map the test set into probability values of the k-clusters. If you have a data point represented by a vector of dimension d, you will map it into a vector of dimension: prob=em_model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 2) [[8.82825926e-242 1.00000000e+000]\n",
      " [9.99999971e-001 2.86754382e-008]\n",
      " [1.00000000e+000 3.11499079e-010]\n",
      " [9.99999999e-001 6.06750093e-010]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 1.34182570e-025]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.99999866e-001 1.34056985e-007]\n",
      " [1.00000000e+000 3.96129622e-019]\n",
      " [6.49078516e-079 1.00000000e+000]\n",
      " [1.00000000e+000 3.20875858e-011]\n",
      " [2.92964245e-014 1.00000000e+000]\n",
      " [1.00000000e+000 3.76670288e-050]\n",
      " [3.25148956e-016 1.00000000e+000]\n",
      " [1.00000000e+000 9.38022003e-012]\n",
      " [1.00000000e+000 9.31629445e-052]\n",
      " [1.00000000e+000 3.34844342e-011]\n",
      " [1.00000000e+000 2.02053855e-027]\n",
      " [1.00000000e+000 6.28733798e-057]\n",
      " [9.99999997e-001 3.11099208e-009]\n",
      " [1.15071200e-001 8.84928800e-001]\n",
      " [1.00000000e+000 4.22865058e-016]\n",
      " [3.32733343e-227 1.00000000e+000]\n",
      " [9.99999995e-001 4.59816784e-009]\n",
      " [1.83046399e-109 1.00000000e+000]\n",
      " [4.05577701e-011 1.00000000e+000]\n",
      " [1.00000000e+000 2.38045421e-016]\n",
      " [1.00000000e+000 1.91731773e-011]\n",
      " [1.00000000e+000 2.47571051e-013]\n",
      " [1.00000000e+000 1.84890993e-035]\n",
      " [9.99999998e-001 1.84229602e-009]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.87799981e-001 1.22000189e-002]\n",
      " [9.99999993e-001 6.86210332e-009]\n",
      " [9.99999918e-001 8.15534894e-008]\n",
      " [2.45870300e-022 1.00000000e+000]\n",
      " [1.00000000e+000 3.76178542e-010]\n",
      " [9.99999592e-001 4.07720755e-007]\n",
      " [9.99999775e-001 2.24654501e-007]\n",
      " [1.00000000e+000 4.45111870e-012]\n",
      " [9.99999786e-001 2.14029527e-007]\n",
      " [5.50443084e-018 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [3.25586896e-101 1.00000000e+000]\n",
      " [9.99999880e-001 1.20106047e-007]\n",
      " [1.34136124e-106 1.00000000e+000]\n",
      " [9.99999999e-001 9.20513256e-010]\n",
      " [1.16113914e-116 1.00000000e+000]\n",
      " [1.00000000e+000 5.14376012e-042]\n",
      " [9.99999786e-001 2.13838149e-007]\n",
      " [2.06518974e-045 1.00000000e+000]\n",
      " [1.00000000e+000 3.46340661e-169]\n",
      " [4.09823852e-018 1.00000000e+000]\n",
      " [7.02239193e-011 1.00000000e+000]\n",
      " [1.72257051e-269 1.00000000e+000]\n",
      " [9.99999998e-001 1.61395183e-009]\n",
      " [9.97026273e-001 2.97372727e-003]\n",
      " [3.19959329e-126 1.00000000e+000]\n",
      " [1.00000000e+000 8.08721501e-016]\n",
      " [1.00000000e+000 2.67198887e-010]\n",
      " [4.63855841e-040 1.00000000e+000]\n",
      " [1.79149975e-021 1.00000000e+000]\n",
      " [9.99999998e-001 1.57258479e-009]\n",
      " [1.00000000e+000 5.67272938e-027]\n",
      " [1.00000000e+000 1.80283222e-018]\n",
      " [6.54579044e-287 1.00000000e+000]\n",
      " [9.99999999e-001 5.83835530e-010]\n",
      " [1.67412262e-055 1.00000000e+000]\n",
      " [9.99999998e-001 1.71699099e-009]\n",
      " [1.00000000e+000 1.61204507e-024]\n",
      " [1.00000000e+000 1.46361635e-021]\n",
      " [1.00000000e+000 3.68606506e-020]\n",
      " [6.17611548e-061 1.00000000e+000]\n",
      " [9.99999974e-001 2.57653134e-008]\n",
      " [1.01431928e-012 1.00000000e+000]\n",
      " [5.19370910e-001 4.80629090e-001]\n",
      " [1.44626198e-009 9.99999999e-001]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.99999222e-001 7.77792194e-007]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.99933952e-001 6.60481068e-005]\n",
      " [1.00000000e+000 1.01847209e-025]\n",
      " [1.99832869e-100 1.00000000e+000]\n",
      " [9.99999158e-001 8.42323364e-007]\n",
      " [1.00000000e+000 6.72921500e-024]\n",
      " [9.97535109e-001 2.46489121e-003]\n",
      " [8.45992738e-047 1.00000000e+000]\n",
      " [1.00000000e+000 3.14232588e-058]\n",
      " [9.96051937e-001 3.94806303e-003]\n",
      " [9.99999742e-001 2.58084346e-007]\n",
      " [6.80374674e-039 1.00000000e+000]\n",
      " [7.26483415e-100 1.00000000e+000]\n",
      " [1.36499109e-005 9.99986350e-001]\n",
      " [1.00000000e+000 3.32798301e-053]\n",
      " [1.00000000e+000 2.28365555e-013]\n",
      " [1.29814242e-021 1.00000000e+000]\n",
      " [3.52337014e-025 1.00000000e+000]\n",
      " [1.00000000e+000 7.37313381e-032]\n",
      " [1.00000000e+000 3.27826109e-011]\n",
      " [5.58955936e-027 1.00000000e+000]\n",
      " [2.09229444e-288 1.00000000e+000]\n",
      " [9.99988321e-001 1.16786477e-005]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 5.31433873e-016]\n",
      " [1.69959152e-078 1.00000000e+000]\n",
      " [1.00000000e+000 7.40982575e-012]\n",
      " [1.14934536e-004 9.99885065e-001]\n",
      " [9.99933698e-001 6.63022313e-005]\n",
      " [9.99999988e-001 1.23340136e-008]\n",
      " [1.20682196e-010 1.00000000e+000]\n",
      " [1.94801230e-009 9.99999998e-001]\n",
      " [1.00000000e+000 7.69676084e-013]\n",
      " [1.00000000e+000 1.49817994e-010]\n",
      " [1.00000000e+000 8.28421002e-017]\n",
      " [9.92651212e-001 7.34878803e-003]\n",
      " [1.00000000e+000 8.93385709e-012]\n",
      " [1.70243690e-007 9.99999830e-001]\n",
      " [9.99775573e-001 2.24427033e-004]\n",
      " [4.05141675e-243 1.00000000e+000]\n",
      " [1.00000000e+000 5.07660405e-024]\n",
      " [1.00000000e+000 5.19143212e-016]\n",
      " [1.00000000e+000 7.99686215e-030]\n",
      " [9.99991385e-001 8.61484350e-006]\n",
      " [2.31645206e-154 1.00000000e+000]\n",
      " [2.56218578e-029 1.00000000e+000]\n",
      " [1.00000000e+000 1.40389463e-014]\n",
      " [1.14544079e-037 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 2.07209759e-025]\n",
      " [9.99913989e-001 8.60110864e-005]\n",
      " [1.00000000e+000 2.68337351e-026]\n",
      " [9.99999945e-001 5.48130018e-008]\n",
      " [1.29493393e-045 1.00000000e+000]\n",
      " [1.00000000e+000 2.71832744e-010]\n",
      " [1.00000000e+000 1.87932894e-017]\n",
      " [9.99999999e-001 9.45322517e-010]\n",
      " [1.00000000e+000 1.90145950e-012]\n",
      " [1.00000000e+000 1.43477921e-024]\n",
      " [1.11235472e-032 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 2.55505396e-022]\n",
      " [1.82828469e-032 1.00000000e+000]\n",
      " [2.00676045e-106 1.00000000e+000]\n",
      " [2.49144361e-075 1.00000000e+000]\n",
      " [1.66271636e-009 9.99999998e-001]\n",
      " [1.00000000e+000 2.21587924e-013]\n",
      " [1.00000000e+000 4.56612562e-022]\n",
      " [6.14321692e-011 1.00000000e+000]\n",
      " [9.99999922e-001 7.83329554e-008]\n",
      " [9.99999914e-001 8.58212988e-008]\n",
      " [9.99999995e-001 5.15000201e-009]\n",
      " [9.99999999e-001 5.85887211e-010]\n",
      " [6.20151878e-003 9.93798481e-001]\n",
      " [5.54231222e-048 1.00000000e+000]\n",
      " [1.40240832e-016 1.00000000e+000]\n",
      " [1.00000000e+000 3.32846382e-010]\n",
      " [5.02157731e-003 9.94978423e-001]\n",
      " [1.00000000e+000 3.42989063e-011]\n",
      " [9.99996892e-001 3.10822470e-006]\n",
      " [7.60855343e-091 1.00000000e+000]\n",
      " [9.99999850e-001 1.50223728e-007]\n",
      " [1.00000000e+000 2.92611088e-018]\n",
      " [9.99998366e-001 1.63363928e-006]\n",
      " [2.05205867e-093 1.00000000e+000]\n",
      " [7.87357838e-011 1.00000000e+000]\n",
      " [1.00000000e+000 1.03350416e-014]\n",
      " [1.00000000e+000 8.88225186e-036]\n",
      " [9.99994855e-001 5.14506333e-006]\n",
      " [1.00000000e+000 5.95665188e-021]\n",
      " [1.08683361e-040 1.00000000e+000]]\n"
     ]
    }
   ],
   "source": [
    "em_model = GaussianMixture(n_components=optimal_k)\n",
    "em_model.fit(X_train)\n",
    "\n",
    "probabilities = em_model.predict_proba(X_test)\n",
    "print(probabilities.shape, probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon analysing the results of the probabilities, we assessed that for many observations there is a big difference between the probabilities for each cluster (for example [1.00000000e+000 1.99228071e-089] where the probability of belonging to the first cluster is almost 1 while the other cluster's probability is very close to 0), which means that the model assings the points to cluster \"confidently\" because the clusters are fairly well-separated for those points. \n",
    "Still, there are a few points where the probabilities are not as different (for example [2.06130572e-001 7.93869428e-001]). This means that for these points, the clusters are overlapped and the model isn't able to attribute the point to a cluster as precisely as for the others.\n",
    "In conclusion, generally, this model is very confident in its attribution of points to clusters and if the clusters correlate well with the target labels (malignant and benign), then these probabilities can serve as features for a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Perform logistic regression on the mapped data set with the labels of the original test set. Indicate now the accuracy. Is there a relation between the number of clusters, the cluster evaluation and the accuracy of the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "X_mapped = probabilities\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_mapped, y_test)\n",
    "\n",
    "y_pred = log_reg.predict(X_mapped)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression applies the sigmoid activation function to the output of a linear regression to classify inputs in 1 of 2 categories. This works because the sigmoid returns a values between 0 and 1 and, with a well defined threshold is possible to predict accurately which class the observations belongs to.\n",
    "\n",
    "Generally (for dataset with continuous outputs), as the number of clusters increases up to a certain point, clustering quality improves because the data is divided into finer partitions that capture more complex patterns. However, beyond this point, adding more clusters begins to decrease clustering quality due to over-segmentation: clusters become too small and fragmented, often capturing noise rather than meaningful patterns.\n",
    "For this particular dataset (categorical), we assessed that the best number of clusters is the k that matches the number of possible outcomes (2). Given this, higher numbers of clusters would be detrimental to the model's performance (as we saw in exercise 2) and worsen the cluster evaluation.\n",
    "With this, we conclude that the number of clusters has an impact on the cluster evaluation.\n",
    "\n",
    "Also, higher-quality clustering indicates that data points within each cluster are more similar to eachother, which helps the logistic regression model to classify observations more accurately, leading to higher accuracy. \n",
    "This suggests a relationship between cluster quality (as measured by cluster evaluation metrics) and the accuracy of the logistic regression model.\n",
    "\n",
    "Given this, it's very important to choose the optimal number of clusters (which heavilly depends on the dataset's properties) to generate the model. This allows better classification of observations and therefore better cluster evaluation proving that there is a relationship between the number of clusters, the cluster evaluation and the accuracy of the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Train an RBF network using the clustering with optimal k  from 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF accuracy: 0.6081871345029239\n",
      "Baseline accuracy: 0.6274165202108963\n"
     ]
    }
   ],
   "source": [
    "centers = em_model.means_\n",
    "\n",
    "X_rbf_transformed = rbf_kernel(X_test, centers)\n",
    "\n",
    "rbf_model = Ridge(alpha=1.0)\n",
    "rbf_model.fit(X_rbf_transformed, y_test)\n",
    "\n",
    "y_rbf_pred = rbf_model.predict(X_rbf_transformed)\n",
    "\n",
    "y_rbf_pred_binary = (y_rbf_pred >= 0.5).astype(int)\n",
    "\n",
    "rbf_accuracy = accuracy_score(y_test, y_rbf_pred_binary)\n",
    "print(f\"RBF accuracy: {rbf_accuracy}\")\n",
    "\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "majority_class_count = np.max(counts) \n",
    "total_samples = len(y)\n",
    "print(f\"Baseline accuracy: {majority_class_count / total_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we obtained an accuracy of 0.6081871345029239, which, alone, indicates a moderate predictive performance for the RBF network. However, when using a naive approach (where the model predicts majority class for all the observations) we obtain a baseline accuracy of 0.6274165202108963 (probability of the class with majority). This is significant because the accuracy with RBF network is lower than the baseline (and the accuracy with logistic regression), meaning that this model underperforms and is currently not appropriate to evalute the dataset.\n",
    "\n",
    "Additionally, there are many factors that can affect the performance of the RBF model, such as clustering quality, feature representation and the overall model's capability.\n",
    "\n",
    "In regards to the clustering quality, we disconsidered slightly this factor because, as seen in the previous exercises the considered clusters are the best that could be obtained for this analysis. Given this, and as the RBF model uses the cluster centers for its training, we concluded that this propably wasn't the most important factor to negativelly affect the model. However, if the clustering had been suboptimal, it could have caused a worsening of the model's performance, specially because clustering adds an inherent layer of abstraction that may discard important details, leading to lower accuracy.\n",
    "\n",
    "As for the feature representation, we could justify the model's poor performance with the fact that the model transforms data points into a new space based on their similarity to the cluster centers. As a consequence, if the test points are not well-matched to the training clusters, the RBF-transformed features may not capture relevant structure needed for accurate predictions.\n",
    "\n",
    "When it comes to the overall model's capability, as it relies on a Ridge regression applied to the transformed data, the transformed features may not provide the needed information for the model to be able to distinguish between classes or, as this regression is linear, it may be too simplistic and limit the model's predictive capability.\n",
    "\n",
    "Given this, we conclude that the obtained accuracy is bellow what is needed for a good machine learning model. This may be due to the cluster's characteristics or the type of regression used in the RBF network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Discuss your findings on a (up to) 5 page document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When describing our findings, we chose to split them in topics corresponding to the exercises to make it easier to understand our analysis. However, in this final part, we summarize the analysis and add a few extra information that didn't match any of the exercises but we found important to point out.\n",
    "\n",
    "1. Achieving an accuracy of around 90-100% with logistic regression on the breast cancer dataset is a solid result, indicating that the model is effective in distinguishing between malignant and benign cases. \n",
    "This suggests that the breast cancer data has features that are well-separated, even by a linear decision boundary. This means the dataset's feature space is structured in a way that a relatively simple model can classify the data accurately.\n",
    "Also, Logistic regression is an interpretable model, which is beneficial for healthcare applications where explainability is important. Achieving high accuracy with a simpler model suggests that logistic regression may provide a good balance of performance and interpretability for this task.\n",
    "High accuracy also implies that the features provided in the breast cancer dataset are relevant and informative for the task of classifying cancer types.\n",
    "\n",
    "2. A score between 0.6 and 0.7 is moderately high, suggesting that the clusters are reasonably well-separated but not perfectly distinct. This indicates that, while the dataset does have inherent structure, there may be some overlap or noise in the features that slightly reduces the separation between clusters.\n",
    "This might reflect real-world scenarios where certain cases have characteristics that are not clearly indicative of one class, suggesting the need for nuanced decision boundaries.\n",
    "Since there is clear clustering into two groups, models like logistic regression (which assumes linear separability) work well for this dataset, as shown by the 90-100% accuracy you obtained earlier. However, the moderate silhouette score also hints that non-linear models, or feature transformations like RBF kernels, could improve performance by capturing more subtle patterns in overlapping areas. \n",
    "In summary, your findings indicate that the breast cancer dataset has a natural separation into two clusters, corresponding to its two classes. However, the overlap suggested by the silhouette score implies that complex decision boundaries may sometimes be necessary to handle borderline cases, even though a simple linear model can perform well for the majority of the data.\n",
    "\n",
    "In addition, as we're dealing with a medical dataset, it's more important to achieve a higher (precision/recall) instead of a higher (precision/recall) because "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
