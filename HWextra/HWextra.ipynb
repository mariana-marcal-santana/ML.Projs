{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Machine Learning Homework 4\n",
    "Done by:\n",
    "Mariana Santana 106992\n",
    "Pedro Leal 106154\n",
    "LEIC-A\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the breast_cancer dataset data = datasets.load_breast_cancer()  with binary target variable y=‘malignant’. Split it 70% for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "General imports and variables for all exercises; run this cell before any other\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Perform logistic regression and indicate the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Perform EM clustering on the training data set with different number k of clusters. Evaluate the quality of the clusterings using Silhouette. Is the number of clusters correlated with the quality of clustering? Which is the optimal k? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Scores: [0.6156295727768908, 0.51306032059586, 0.5008310013511474, 0.43666220370687076, 0.43722891298798, 0.4386005228373668, 0.4546850794327086, 0.43917931395798343]\n",
      "Optimal number of clusters: 2\n"
     ]
    }
   ],
   "source": [
    "k_values = range(2, 10)\n",
    "\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    gmm = GaussianMixture(n_components=k)\n",
    "    gmm.fit(X_train)\n",
    "    labels = gmm.predict(X_train)\n",
    "    score = silhouette_score(X_train, labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "print(\"Silhouette Scores:\", silhouette_scores)\n",
    "optimal_k = k_values[np.argmax(silhouette_scores)]\n",
    "print(\"Optimal number of clusters:\", optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon performing EM clustering, we obtained the silhouette scores for the different number of clusters ([0.6953546812827253, 0.6460072951798395, 0.44240066859293997, 0.40975176230240173, 0.4342973431576532, 0.4192675100180935, 0.4273557130544327, 0.4203979188373632] in order from 2 to 9 clusters).\n",
    "\n",
    "We also know that overall silhouette score (average of the silhouettes of the individual points of the dataset) is used to evaluate the quality of clustering results. The individual silhouettes can range between -1 and 1 where lower values mean that the point has probably been assigned to the wrong cluster while higher values mean that the point matches nearly perfectly its neighbors (points of the same cluster) and very poorly points of different cluster, resulting in a better assignment of points to clusters. The overall silhouette of the model ranges between the same values as the previously explained silhouettes. For genereal interpretation, lower values suggest bad organization of points in clusters while values closer to 1 correspond to a lower intra-cluster distance (points in the same cluster are close to eachother) and higher inter-cluster distance (clusters are far apart from eachother).\n",
    "\n",
    "Given this, when analysing the varying results, we concluded that the number of clusters impacts the model's quality of clustering. This happens because the number of clusters has an effect in cohesion and separation (with too few cluster the model has low separation and high cohesion - points within clusters are not very similar and clusters may overlap and with too many clusters can lead to overfitting - clusters become too small and lose their generality). \n",
    "\n",
    "After this analysis, we concluded that there needed to be a balance in the model's cohesion and separation which are directly linked to its silhouette: the higher silhouette value belonged to k=2 (0.6953546812827253) which corresponds to the optimal number of cluster for this model and this data. This conclusion makes a lot of sense for this exercise because there are 2 possible outcomes (benign and malignant) and therefore 2 clusters to classify observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Map the test set into probability values of the k-clusters. If you have a data point represented by a vector of dimension d, you will map it into a vector of dimension: prob=em_model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 2) [[1.00000000e+000 1.14215983e-014]\n",
      " [6.65112734e-046 1.00000000e+000]\n",
      " [9.99999999e-001 1.11210288e-009]\n",
      " [9.99995236e-001 4.76366919e-006]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.98319350e-001 1.68064986e-003]\n",
      " [2.79583738e-005 9.99972042e-001]\n",
      " [9.99998709e-001 1.29100970e-006]\n",
      " [3.07980895e-126 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 6.53312135e-023]\n",
      " [9.99999785e-001 2.15142495e-007]\n",
      " [1.00000000e+000 8.03337744e-013]\n",
      " [1.00000000e+000 8.75465571e-013]\n",
      " [3.16230108e-035 1.00000000e+000]\n",
      " [9.99999861e-001 1.39349573e-007]\n",
      " [1.00000000e+000 3.28438603e-019]\n",
      " [1.00000000e+000 7.25384451e-014]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.99331452e-001 6.68547975e-004]\n",
      " [1.41108937e-053 1.00000000e+000]\n",
      " [1.41884563e-045 1.00000000e+000]\n",
      " [1.00000000e+000 2.82868584e-010]\n",
      " [1.00000000e+000 9.59806240e-028]\n",
      " [1.82316973e-001 8.17683027e-001]\n",
      " [1.01751604e-088 1.00000000e+000]\n",
      " [1.00000000e+000 1.66670106e-026]\n",
      " [8.20853921e-031 1.00000000e+000]\n",
      " [8.53514204e-014 1.00000000e+000]\n",
      " [7.05078973e-034 1.00000000e+000]\n",
      " [1.00000000e+000 2.93377945e-025]\n",
      " [2.42113897e-095 1.00000000e+000]\n",
      " [9.99992955e-001 7.04547894e-006]\n",
      " [1.07731014e-314 1.00000000e+000]\n",
      " [3.33934069e-001 6.66065931e-001]\n",
      " [9.99301246e-001 6.98753705e-004]\n",
      " [1.00000000e+000 3.03145846e-013]\n",
      " [2.71882020e-172 1.00000000e+000]\n",
      " [1.00000000e+000 5.79874830e-012]\n",
      " [9.98773784e-001 1.22621563e-003]\n",
      " [1.00000000e+000 1.26561656e-057]\n",
      " [6.76682649e-048 1.00000000e+000]\n",
      " [1.44859777e-182 1.00000000e+000]\n",
      " [3.83213261e-039 1.00000000e+000]\n",
      " [1.00000000e+000 2.63939520e-024]\n",
      " [1.00000000e+000 6.52590118e-031]\n",
      " [9.99999995e-001 5.24055814e-009]\n",
      " [9.19723484e-001 8.02765161e-002]\n",
      " [1.08350244e-002 9.89164976e-001]\n",
      " [1.00000000e+000 1.36085983e-012]\n",
      " [1.75801703e-090 1.00000000e+000]\n",
      " [1.00000000e+000 7.62154483e-033]\n",
      " [9.99999999e-001 1.20828568e-009]\n",
      " [1.00000000e+000 1.85975944e-038]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.93291398e-001 6.70860188e-003]\n",
      " [9.99438940e-001 5.61060019e-004]\n",
      " [1.63480819e-105 1.00000000e+000]\n",
      " [9.99946709e-001 5.32912886e-005]\n",
      " [1.36594307e-002 9.86340569e-001]\n",
      " [9.99999998e-001 1.89044503e-009]\n",
      " [6.05010879e-083 1.00000000e+000]\n",
      " [9.99999999e-001 7.43829968e-010]\n",
      " [9.98395281e-001 1.60471886e-003]\n",
      " [1.00000000e+000 2.09026485e-027]\n",
      " [1.00000000e+000 2.14740855e-037]\n",
      " [6.84311353e-198 1.00000000e+000]\n",
      " [9.99999990e-001 9.91370983e-009]\n",
      " [1.00000000e+000 3.82297777e-047]\n",
      " [1.00000000e+000 9.10608125e-025]\n",
      " [1.00000000e+000 5.23412185e-011]\n",
      " [9.99890572e-001 1.09428450e-004]\n",
      " [1.00000000e+000 4.54906445e-035]\n",
      " [1.00000000e+000 2.48589659e-042]\n",
      " [4.12188799e-075 1.00000000e+000]\n",
      " [3.70822722e-131 1.00000000e+000]\n",
      " [9.99999991e-001 9.44776949e-009]\n",
      " [1.00000000e+000 1.07321313e-013]\n",
      " [1.00000000e+000 4.16419848e-013]\n",
      " [1.00000000e+000 3.29832292e-022]\n",
      " [3.59361274e-001 6.40638726e-001]\n",
      " [7.06648273e-079 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.99992030e-001 7.96965338e-006]\n",
      " [1.00000000e+000 2.04652081e-027]\n",
      " [1.00000000e+000 7.18641980e-011]\n",
      " [1.02429638e-120 1.00000000e+000]\n",
      " [1.00000000e+000 1.11446188e-012]\n",
      " [1.00000000e+000 4.29516764e-032]\n",
      " [1.00000000e+000 1.23429261e-037]\n",
      " [9.99999998e-001 2.02756139e-009]\n",
      " [1.00000000e+000 2.96980179e-068]\n",
      " [9.98941918e-001 1.05808156e-003]\n",
      " [8.54948855e-152 1.00000000e+000]\n",
      " [1.41489935e-004 9.99858510e-001]\n",
      " [9.99146669e-001 8.53330524e-004]\n",
      " [1.00000000e+000 3.43895628e-081]\n",
      " [9.95898971e-001 4.10102851e-003]\n",
      " [1.00000000e+000 5.75874203e-033]\n",
      " [7.75216741e-110 1.00000000e+000]\n",
      " [1.00000000e+000 5.63542454e-024]\n",
      " [1.00000000e+000 1.69313640e-047]\n",
      " [1.71385830e-005 9.99982861e-001]\n",
      " [2.04060043e-006 9.99997959e-001]\n",
      " [1.00000000e+000 1.22252163e-025]\n",
      " [1.00000000e+000 4.51516844e-041]\n",
      " [1.00000000e+000 1.33622837e-019]\n",
      " [4.87258078e-122 1.00000000e+000]\n",
      " [9.99999999e-001 8.47070654e-010]\n",
      " [9.99984417e-001 1.55831405e-005]\n",
      " [1.12857527e-030 1.00000000e+000]\n",
      " [8.10313232e-001 1.89686768e-001]\n",
      " [1.00000000e+000 3.50579551e-018]\n",
      " [1.00000000e+000 1.16773611e-021]\n",
      " [1.00000000e+000 4.80053521e-096]\n",
      " [1.00000000e+000 2.12259598e-010]\n",
      " [9.99999838e-001 1.62184513e-007]\n",
      " [1.00000000e+000 1.49399916e-056]\n",
      " [4.13399864e-046 1.00000000e+000]\n",
      " [9.99999667e-001 3.32516293e-007]\n",
      " [1.00000000e+000 3.74451364e-029]\n",
      " [1.00000000e+000 2.19389124e-020]\n",
      " [9.74248866e-001 2.57511343e-002]\n",
      " [1.00000000e+000 1.81182668e-079]\n",
      " [9.99995610e-001 4.38985147e-006]\n",
      " [1.00000000e+000 2.35202648e-021]\n",
      " [1.80186304e-005 9.99981981e-001]\n",
      " [1.00000000e+000 1.18082674e-056]\n",
      " [6.94899450e-008 9.99999931e-001]\n",
      " [5.20024965e-005 9.99947998e-001]\n",
      " [1.00000000e+000 8.20028508e-011]\n",
      " [9.99987587e-001 1.24131061e-005]\n",
      " [9.99999727e-001 2.72817943e-007]\n",
      " [1.00000000e+000 2.06734821e-014]\n",
      " [1.00000000e+000 1.36567734e-027]\n",
      " [8.93475914e-023 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 1.93449727e-016]\n",
      " [1.00000000e+000 3.26437480e-010]\n",
      " [9.99953660e-001 4.63396861e-005]\n",
      " [9.99999996e-001 3.58094926e-009]\n",
      " [1.41005623e-123 1.00000000e+000]\n",
      " [9.99999388e-001 6.12290162e-007]\n",
      " [1.00000000e+000 2.60596137e-018]\n",
      " [9.99989189e-001 1.08108489e-005]\n",
      " [7.97412260e-038 1.00000000e+000]\n",
      " [9.99999943e-001 5.67791731e-008]\n",
      " [9.99999938e-001 6.15920300e-008]\n",
      " [1.00000000e+000 1.17224164e-014]\n",
      " [1.52725195e-004 9.99847275e-001]\n",
      " [9.99999928e-001 7.16843522e-008]\n",
      " [1.00000000e+000 1.18592588e-012]\n",
      " [9.99999998e-001 1.78536587e-009]\n",
      " [9.99978974e-001 2.10255940e-005]\n",
      " [1.96149924e-179 1.00000000e+000]\n",
      " [9.99999995e-001 4.89159096e-009]\n",
      " [1.00000000e+000 1.05987442e-018]\n",
      " [9.47458279e-084 1.00000000e+000]\n",
      " [1.00000000e+000 9.35375364e-022]\n",
      " [3.62006441e-002 9.63799356e-001]\n",
      " [2.02406053e-001 7.97593947e-001]\n",
      " [1.00000000e+000 2.04527935e-022]\n",
      " [2.40413700e-065 1.00000000e+000]\n",
      " [1.93356725e-216 1.00000000e+000]\n",
      " [1.00000000e+000 4.17383749e-044]\n",
      " [9.48186965e-013 1.00000000e+000]\n",
      " [9.88415689e-001 1.15843109e-002]\n",
      " [9.97995985e-001 2.00401485e-003]\n",
      " [1.00000000e+000 1.57675446e-016]\n",
      " [1.00000000e+000 5.73998584e-021]\n",
      " [9.99899301e-001 1.00698766e-004]]\n"
     ]
    }
   ],
   "source": [
    "em_model = GaussianMixture(n_components=optimal_k)\n",
    "em_model.fit(X_train)\n",
    "\n",
    "probabilities = em_model.predict_proba(X_test)\n",
    "print(probabilities.shape, probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Perform logistic regression on the mapped data set with the labels of the original test set. Indicate now the accuracy. Is there a relation between the number of clusters, the cluster evaluation and the accuracy of the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "X_mapped = probabilities\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_mapped, y_test)\n",
    "\n",
    "y_pred = log_reg.predict(X_mapped)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression applies the sigmoid activation function to the output of a linear regression to classify inputs in 1 of 2 categories. This works because the sigmoid returns a values between 0 and 1 and, with a well defined threshold is possible to predict accurately with class the observations belongs to.\n",
    "\n",
    "Generally (for dataset with continuous outputs), as the number of clusters increases up to a certain point, clustering quality improves because the data is divided into finer partitions that capture more complex patterns. However, beyond this point, adding more clusters begins to decrease clustering quality due to over-segmentation: clusters become too small and fragmented, often capturing noise rather than meaningful patterns.\n",
    "For this particular dataset (categorical), we assessed that the best number of clusters is the k that matches the number of possible outcomes (2). Given this, higher numbers of clusters would be detrimental to the model's performance (as we saw in exercise 2) and worsen the cluster evaluation.\n",
    "With this, we conclude that the number of clusters has an impact on the cluster evaluation.\n",
    "\n",
    "--\n",
    "\n",
    "Also, higher-quality clustering indicates that data points within each cluster are more similar to eachother, which helps the logistic regression model to classify observations more accurately, leading to higher accuracy. \n",
    "This suggests a relationship between cluster quality (as measured by cluster evaluation metrics) and the accuracy of the logistic regression model.\n",
    "\n",
    "--\n",
    "\n",
    "Given this, it's very important to choose the optimal number of clusters (which heavilly depends on the dataset's properties) to generate the model. This allows better classification of observations and therefore better cluster evaluation proving that there is a relationship between the number of clusters, the cluster evaluation and the accuracy of the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Train an RBF network using the clustering with optimal k  from 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6198830409356725\n"
     ]
    }
   ],
   "source": [
    "centers = em_model.means_\n",
    "\n",
    "X_rbf_transformed = rbf_kernel(X_test, centers)\n",
    "\n",
    "rbf_model = Ridge(alpha=1.0)\n",
    "rbf_model.fit(X_rbf_transformed, y_test)\n",
    "\n",
    "y_rbf_pred = rbf_model.predict(X_rbf_transformed)\n",
    "\n",
    "y_rbf_pred_binary = (y_rbf_pred >= 0.5).astype(int)\n",
    "\n",
    "rbf_accuracy = accuracy_score(y_test, y_rbf_pred_binary)\n",
    "print(rbf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Discuss your findings on a (up to) 5 page document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
