{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Machine Learning Homework 1\n",
    "Done by:\n",
    "Mariana Santana 106992\n",
    "Pedro Leal 106154\n",
    "LEIC-A\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Programming\n",
    "#### Consider the diabetes.arff data available at the homework tab, comprising 8 biological features to classify 768 patients into 2 classes (normal, diabetes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f_classif, mutual_info_classif\n\u001b[1;32m     10\u001b[0m dataset \u001b[38;5;241m=\u001b[39m arff\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiabetes.arff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m attribute_names \u001b[38;5;241m=\u001b[39m [attr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattributes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     12\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m {attr: [] \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m attribute_names}\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "General imports and variables for all exercises; run this cell before any other\n",
    "\"\"\"\n",
    "\n",
    "import arff, pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "\n",
    "dataset = arff.load(open(\"diabetes.arff\", \"r\"))\n",
    "attribute_names = [attr[0] for attr in dataset['attributes']]\n",
    "data_dict = {attr: [] for attr in attribute_names}\n",
    "\n",
    "for row in dataset['data']:\n",
    "    for i, value in enumerate(row):\n",
    "        data_dict[attribute_names[i]].append(value)\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "X, y = df.drop('Outcome', axis=1), df['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ANOVA is a statistical test that can be used to assess the discriminative power of a single input variable. Using f_classif from sklearn, identify the input variables with the worst and best discriminative power. Plot their class-conditional probability density functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_classif' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f_values, p_values \u001b[38;5;241m=\u001b[39m \u001b[43mf_classif\u001b[49m(X, y)\n\u001b[1;32m      3\u001b[0m feature_scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF-Value\u001b[39m\u001b[38;5;124m'\u001b[39m: f_values,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp-Value\u001b[39m\u001b[38;5;124m'\u001b[39m: p_values\n\u001b[1;32m      7\u001b[0m })\n\u001b[1;32m      9\u001b[0m feature_scores \u001b[38;5;241m=\u001b[39m feature_scores\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF-Value\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f_classif' is not defined"
     ]
    }
   ],
   "source": [
    "f_values, p_values = f_classif(X, y)\n",
    "\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'F-Value': f_values,\n",
    "    'p-Value': p_values\n",
    "})\n",
    "\n",
    "feature_scores = feature_scores.sort_values(by='F-Value', ascending=False)\n",
    "best_feature = feature_scores.iloc[0]['Feature']\n",
    "worst_feature = feature_scores.iloc[-1]['Feature']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.kdeplot(df[best_feature][df['Outcome'] == '1'], label='Diabetes', color='r', fill=True)\n",
    "sns.kdeplot(df[best_feature][df['Outcome'] == '0'], label='Normal', color='b', fill=True)\n",
    "plt.title(f'Class-Conditional Density Plot for Best Feature: {best_feature}')\n",
    "plt.xlabel(best_feature)\n",
    "plt.ylabel('Probability Density')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.kdeplot(df[worst_feature][df['Outcome'] == '1'], label='Diabetes', color='r')\n",
    "sns.kdeplot(df[worst_feature][df['Outcome'] == '0'], label='Normal', color='b')\n",
    "plt.title(f'Class-Conditional Density Plot for Worst Feature: {worst_feature}')\n",
    "plt.xlabel(worst_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using a stratified 80-20 training-testing split with a fixed seed (random_state=1), assess in a single plot both the training and testing accuracies of a decision tree with minimum sample split in {2,5,10,20,30,50,100} and the remaining parameters as default. Note that split thresholding of numeric variables in decision trees is non-deterministic in sklearn, hence you may opt to average the results using 10 runs per parameterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split_values = [2, 5, 10, 20, 30, 50, 100]\n",
    "n_runs, random_state = 10, 1\n",
    "train_accuracies, test_accuracies = [], []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=random_state)\n",
    "\n",
    "feature_scores = mutual_info_classif(X_train, y_train)\n",
    "sorted_features = np.argsort(feature_scores)\n",
    "\n",
    "for m in min_samples_split_values:\n",
    "\n",
    "    train_m_acc, test_m_acc = [], []\n",
    "    predictor = tree.DecisionTreeClassifier(min_samples_split=m, random_state=random_state)\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "        top_features = sorted_features[-m:]\n",
    "        X_m_train, X_m_test = X_train.iloc[:, top_features], X_test.iloc[:, top_features]\n",
    "\n",
    "        predictor.fit(X_m_train, y_train)\n",
    "        train_m_acc.append(metrics.accuracy_score(y_train, predictor.predict(X_m_train)))\n",
    "        test_m_acc.append(metrics.accuracy_score(y_test, predictor.predict(X_m_test)))\n",
    "    \n",
    "    train_accuracies.append(np.mean(train_m_acc))\n",
    "    test_accuracies.append(np.mean(test_m_acc))\n",
    "\n",
    "print(\"Train accuracies: \", train_accuracies, \"\\nTest accuracies: \", test_accuracies)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(min_samples_split_values, train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(min_samples_split_values, test_accuracies, label='Testing Accuracy', marker='o')\n",
    "plt.title('Training and Testing Accuracies')\n",
    "plt.xlabel('Minimum Sample Splits')\n",
    "plt.ylim(0.5, 1.1)\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Critically analyze these results, including the generalization capacity across settings.\n",
    "With the analysis of the resulting plot from exercise 2, it is possible to assess the relation between the training accuracy and the testing accuracy.\n",
    "\n",
    "For lower min_sample_split values (0-20) there is an inverse relation between the accuracies, that is, the model gets overfitted because it memorizes the data instead of generalizing patterns. \n",
    "\n",
    "On the other hand, for values beyond 40 the testing accuracy drops slightly, suggesting underfitting as the model becomes too simple to capture data patterns effectively.\n",
    "\n",
    "In conclusion, for this particular situation, the best value for min_sample_split would be around 30 becuase that's where we see a peak in testing accuracy suggesting a better model overall, balancing between high training accuracy and good generalization to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. To deploy the predictor, a healthcare provider opted to learn a single decision tree (random_state=1) using all available data and ensuring that the maximum depth would be 3 in order to avoid overfitting risks. \n",
    "#### i. Plot the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "clf.fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "tree.plot_tree(clf, feature_names=X.columns, class_names=['Normal', 'Diabetes'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Explain what characterizes diabetes by identifying the conditional associations together with their posterior probabilities.\n",
    "\n",
    "The main features that characterize diabetes are: Glucose, BMI and Age.\n",
    "\n",
    "P(class = Diabetes) = 3/4, when Glucose <= 127.5, Age <= 28.5 and BMI > 45.4.\n",
    "P(class = Diabetes) = 174/283, when Glucose > 127.5.\n",
    "P(class = Diabetes) = 150/207, when Glucose > 127.5 and BMI > 29.95.\n",
    "P(class = Diabetes) = 80/92, when Glucose > 157.5 and BMI > 29.95.\n",
    "P(class = Diabetes) = 70/115, when 127.5 < Glucose <= 157.5 and BMI > 29.95.\n",
    "P(class = Diabetes) = 18/35, when Glucose > 145.5 and BMI <= 29.95.\n",
    "\n",
    "### PERGUNTAR\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
